{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbres de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision : Quésaco ? <a class=\"anchor\" id=\"def\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un arbre de décision est un modèle d'apprentissage supervisé simple.  <br>\n",
    "\n",
    "Les arbres de décision, plus précisémment les forêts aléatoires (Random Forest), sont largement utilisées en entreprise pour faciliter le processus de prise de décision et l'analyse des risques.  Leur structure arborescente les rend lisibles par un être humain, contrairement à d'autres modèles où le prédicteur construit une \"boite noire\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types d'arbre de décision <a class=\"anchor\" id=\"types\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe deux arbres de décision :\n",
    "\n",
    "* **Arbres de régression (Regression Tree)**: <br> \n",
    "Ils sont utilisés pour répondre à des problèmes de régression où la valeur de sortie (target ou variable explicative) est une variable continue. Pour prédire cette variable, l'étiquette de chaque feuille de l'arbre est la moyenne des valeurs. \n",
    "* **Arbres de classification (Classification Tree)**<br>\n",
    "Ils sont utilisés pour répondre à des problèmes de classification où la valeur de sortie est une variable catégorielle. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation avec sklearn <a class=\"anchor\" id=\"code_exemple\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modèle de classification avec des arbres de décision peut être implémenté avec la classe <a https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier\">DecisionTreeClassifier</a> du package *sklearn.tree*<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeu de données\n",
    "**Question 1** : <br>\n",
    "Charger le jeu de données <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.breast_cancer.html?highlight=diabetes#sklearn.datasets.breast_cancer\">breast_cancer</a> de sklearn \n",
    "* Utiliser la fonction *load_breast_cancer()* du package *sklearn.datasets*\n",
    "* Affecter les features à la variable X\n",
    "* Affecter la target à la variable y\n",
    "* Afficher la description du jeu de données en utilisant l'attribut *DESCR* du dictionnaire data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
    "X, y = breast_cancer['data'], breast_cancer['target']\n",
    "breast_cancer.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données d'entraînement et de test\n",
    "**Question 2** :<br>\n",
    "Diviser le jeu de données en jeu de données d'entraînement (70%) et de test (30%) en utilisant la fonction *train_test_split* du package *sklearn.model_selection* \n",
    "* paramètres : random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** :<br>\n",
    "Comment le paramètre *random_state* influence le split du dataset ? <br>\n",
    "**Ressources** \n",
    "<a href=\"https://www.bitdegree.org/learn/train-test-split\">Splitting Datasets With the Sklearn train_test_split Function</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_state is the object that controls randomization during splitting. It can be either an int or an instance of RandomState. The default value is None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle | DecisionTreeClassifier\n",
    "**Question 4** :<br>\n",
    "Créer l'objet *classifier* de la classe <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">*DecisionTreeClassifier*</a> du package *sklearn.tree*. <br>\n",
    "Utiliser les paramètres par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du l'arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** : <br>Utiliser la méthode *fit* de la classe *DecisionTreeClassifier* pour entraîner le modèle d'arbre de classification *classifier* en utilisant les données d'entraînement *X_train* et *y_train* (algorithme supervisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction\n",
    "**Question 6** : <br>\n",
    "Prédire si un patient a une tumeur maligne ou bénine en utilisant le modèle entraîné précédemment et la méthode *predict* de la classe *DecisionTreeClassifier* avec comme paramètre les données de test *y_test*.<br>\n",
    "Stocker le résultat de la prédiction dans la variable y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation de l'arbre de décision\n",
    "Il existe plusieurs manière pour visualiser l'arbre de décision pour une meilleure lisibilité et interprétation du modèle. <br>\n",
    "Ressource : <a href=\"https://towardsdatascience.com/visualizing-decision-trees-with-python-scikit-learn-graphviz-matplotlib-1c50b4aa68dc\">*Visualizing DEcision Trees with Python (Scikit-lean, Graphiz, Matplotlib*</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7** : <br>\n",
    "Visualiser le modèle *classifier* en utilisant <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree\">*plot_tree*</a> du package *sklearn.tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8** : <br>\n",
    "Visualiser le modèle classifier en utilisant<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz\"> *Graphiz*</a> <br>\n",
    "Intaller le package <a href=\"https://anaconda.org/conda-forge/python-graphviz\">*Graphiz*</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(classifier);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9** :<br>\n",
    "L'arbre généré est-il exploitable ? <br>\n",
    "Conclure !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frère c'est chaud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation \n",
    "**Question 10** : <br>\n",
    "Evaluer la qualité du modèle en utilisant la méthode *score* de la classe *DecisionTreeClassifier* pour les données d'entraînement et de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(classifier.score(X_test, y_test))\n",
    "print(classifier.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intérpretation  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11** :<br> \n",
    "A quoi correspond le critère d'évaluation utilisé pour le calcul du score ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know man, leave me alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12** :<br>\n",
    "Comparez les deux scores et conclure !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision est pas mal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin première partie <br>\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithmes de construction des arbres de décision<a class=\"anchor\" id=\"algos\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14** : <br>\n",
    "* Citer les différents algorithmes d'arbres de décision. \n",
    "* Quel est l'algorithme implémenté dans scikit learn ? \n",
    "**Ressource** : <br>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/tree.html#\">Decision Trees - Scikit Learn</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **ID3 Iterative Dichotomiser 3** <br>\n",
    " \n",
    "* **C4.5** <br>\n",
    "\n",
    "* **C5.0** <br>\n",
    "\n",
    "* **CART Classification And Regression Trees** <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple <a class=\"anchor\" id=\"exemple\"></a> <br>\n",
    "Pour mieux comprendre comment l'arbre de décision est construit, un exemple est détaillé <a href=\"https://www.saedsayad.com/decision_tree_reg.htm#:~:text=Decision%20tree%20builds%20regression%20or,decision%20nodes%20and%20leaf%20nodes\">ici</a>. <br>\n",
    "L'exemple utilise l'algorithme ID3, qui est la base de CART utilisé par scikit learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15**: <br>\n",
    "En utilisant l'arbre de décision de l'exemple précédent, prédire le nombre d'heures jouées dans les conditions suivantes : [Outlook = Sunny,Temp = Mild ,Humidity = High, Windy = False] ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heures jouées prédites = ... <br>\n",
    "heures jouées réeels = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin deuxième partie <br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application : prédire le type d'Iris <a class=\"anchor\" id=\"boston\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeu de données \n",
    "**Question 16** : <br>\n",
    "Charger le jeu de données <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html?highlight=boston#sklearn.datasets.load_boston\">boston house-prices</a> de sklearn <br>\n",
    "Tips : \n",
    "* Utiliser la fonction *load_boston()* du package *sklearn.datasets*. Le résultat est affecté à la variable *dataset*\n",
    "* Afficher la description du jeu de données en utilisant l'attribut *DESCR* du dictionnaire data. \n",
    "* Transformer le *dataset* à un DataFrame, *df*, en utilisant *pandas* et les attributs *data* et *feature_names* du dictionnaire *data*\n",
    "* Créer une variable $X$ qui représente les variables explicatives. Pour cet exemple, on se limite aux variables 'RM', 'LSTAT' et 'PTRATIO'\n",
    "* Créer une variable $y$ qui contient la variable expliquée (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données d'entraînement et de test\n",
    "**Question 17** : <br>\n",
    "Quel est l'avantage de diviser le jeu de données en données d'apprentissage et des données de test ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 18** :<br>\n",
    "Diviser le jeu de données en jeu de données d'entraînement (80%) et de test (20%) en utilisant la fonction *train_test_split* du package *sklearn.model_selection* \n",
    "* paramètres : random_state = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 19** :<br>\n",
    "Quelle est la limite de la métode train_test_split sur la précision ? comment pallier à cette limite ? <br>\n",
    "**Tips :** <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\">K-Folds cross-validation</a>, <a href=\"https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search\">Grid Search</a> <br>\n",
    "\n",
    "**Ressources**\n",
    "* <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html?highlight=cross_validation\">Cross-validation scikit learn</a>\n",
    "* <a href=\"https://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85\">Cross Validation Explained: Evaluating estimator performance.</a>\n",
    "* <a href=\"http://www.xavierdupre.fr/app/papierstat/helpsphinx/notebooks/wines_knn_cross_val.html\">Validation croisée</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle | DecisionTreeClassifier\n",
    "**Question 20** : <br>\n",
    "Utiliser la classe <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html?highlight=decisiontreeregressor#sklearn.tree.DecisionTreeClassifier\">*DecisionTreeClassifier*</a> du package *sklearn.tree* pour créer l'objet *classifier*<br>\n",
    "Utiliser les paramètres par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 21** :<br> Quels sont les paramètres de la classe *DecisionTreeClassifier* qui influencent la performance de l'algorithme ?  <br>\n",
    "**Ressources** <br>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeregressor#sklearn.tree.DecisionTreeClassifier\">DecisionTreeClassifier</a> <br>\n",
    "<a href=\"https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3\">InDepth : Parameter tuning for Decision Tree (classification)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres à optimiser pour un arbre de décision optimal sont les suivants : \n",
    "* \n",
    "*\n",
    "*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 22** :  <br>\n",
    "Créer les deux sous-ensemble de données d'apprentissage et de test en utilisant la technique de validation croisée. <br>\n",
    "Stocker le résultat dans la variable *cv_sets*. <br>\n",
    "Utiliser les paramètres suivants :\n",
    "* $n\\_splits$ = $10$\n",
    "* $shuffle$ = $True$ \n",
    "* $random\\_state$ = $42$ <br>\n",
    "Tips : Utiliser la classe <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=kfold#sklearn.model_selection.KFold\">*KFold*</a> du package *sklearn.model-selection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** : Dans ce qui suit, on se focalisera sur le premier paramètre, à savoir, **max_depth**. Le même raisonnement peut être appliqué à chacun des paramètres ou à une combinaison de paramètres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement de l'arbre de décision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimisation du paramètre max_depth\n",
    "Pour trouver la valeur du paramètre max_depth qui donne le meilleur estimateur (meilleur arbre de décision), on utilise la classe <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV\">GridSearchCV</a>. <br>\n",
    "Pour cela, il faut suivre les étapes suivantes !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 23** : <br>\n",
    "Créer un dictionnaire pour *max_depth* avec les valeurs de 1 à 10. <br>\n",
    "Affecter-le à la variable *params*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 24** : <br>\n",
    "Créer un objet grid search en utilisant la classe <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV\">*GridSearchCV*</a> du package *sklearn.model_selection*\n",
    "* paramètres : classifier, params, score=\"accuracy\", cv_sets\n",
    "* variable : grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 25** :<br>\n",
    "Entraîner le méta estimateur grid_cv pour trouver l'estimateur optimal en utilisant la méthode *fit*. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 26** : <br>\n",
    "Quel est le meilleur modèle ? <br>\n",
    "Stocker le meilleur modèle dans la variable *best_tree*<br>\n",
    "**Tips** : Utiliser l'attribut *best_estimator_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 27** : <br>\n",
    "Quelle est la profondeur maximale (*max_depth*) du modèle optimal (best_tree) ? <br>\n",
    "**Tips** : Utiliser l'attribut *best_params_* de la classe *GridSearchCV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 30** : <br>\n",
    "Prédire le type d'Iris pour les données de test *X_test*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intérpretation  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 31** : <br>\n",
    "Intérpreter les résultats (la prédiction semble logique ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin troisième partie \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Courbe d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 32** : <br>\n",
    "Qu'est ce que la courbre d'apprentissage ? <br>\n",
    "**Ressource** : <a href=\"https://fr.qaz.wiki/wiki/Learning_curve_(machine_learning)\">Courbe d'apprentissage</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 33** :<br>\n",
    "Afficher la **courbe d'apprentissage** du classifier en utilisant la méthode *plot_learning_curve* du module *estimators* de scikit plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 34** : <br>\n",
    "Interpréter les graphiques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin : <a class=\"anchor\" id=\"post_pruning\"></a>\n",
    "<a href=\"https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py\">Post élagage avec scikit learn | Exemple </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
